{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660850c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72067e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import plotly.express as px\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a508e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_uri = \"http://localhost:8000\"\n",
    "experiment_name = \"llm2model2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d668a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a21da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(search_all_experiments=True)\n",
    "runs  = runs[runs[\"tags.mlflow.parentRunId\"].isnull()]\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs['output_dim_numeric'] = runs['params.output_dim'].replace('None', None)\n",
    "runs['output_dim_numeric'] = pd.to_numeric(runs['output_dim_numeric'], errors='coerce', downcast = \"integer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1077f",
   "metadata": {},
   "source": [
    "# Comparing the different hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3268950",
   "metadata": {},
   "source": [
    "### Dimension reduction hurts the performance but is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_names = [\"dimNone\",\"dim4096\", \"dim2048\", \"dim1024\", \"dim512\", \"dim256\"]\n",
    "rs = runs[runs['tags.mlflow.runName'].isin(run_names)]\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a10d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_groupby = rs.groupby([\"params.output_dim\", \"metrics.raw_accuracy\"]).count()\n",
    "rs_groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183c6a4",
   "metadata": {},
   "source": [
    "All of the runs with output_dim of 256 have the same performance, so we will pick the first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = rs.groupby([\"params.output_dim\", \"metrics.raw_accuracy\"]).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3818d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rs = rs.reset_index().sort_values(by='output_dim_numeric', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70071d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs[[\"params.output_dim\", \"metrics.raw_accuracy\",\"output_dim_numeric\"]].sort_values(\"output_dim_numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(rs, x = \"params.output_dim\", y = \"metrics.raw_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97504e11",
   "metadata": {},
   "source": [
    "Apparently, going from no PCA to PCA with same dimensions gives a performance boost. \n",
    "\n",
    "Otherwise, the fewer the dimensions, the lower the accuracy (as expected). We will stick to 256 because we want small model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89bdef",
   "metadata": {},
   "source": [
    "### Normalization of final embedding improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = runs[(runs['tags.mlflow.runName'].str.contains(\"normalize_embeddings\")) | (runs['tags.mlflow.runName']==\"dim256\")]\n",
    "rs = rs.groupby(\"tags.mlflow.runName\").first()\n",
    "rs['params.normalize_embeddings'] = rs['params.normalize_embeddings'].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs['params.normalize_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e47de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(rs, x = \"params.normalize_embeddings\", y = \"metrics.raw_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6271d4",
   "metadata": {},
   "source": [
    "Pretty big performance enhancement to normalize embeddings. So this is definately a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aab2f4",
   "metadata": {},
   "source": [
    "### There is a sweetspot for SIF coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = runs[(runs['tags.mlflow.runName'].str.contains(\"sif\")) | (runs['tags.mlflow.runName']==\"dim256\")]\n",
    "rs = rs.groupby(\"tags.mlflow.runName\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab399cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(rs.sort_values(by = \"params.sif_coefficient\"), x = \"params.sif_coefficient\", y = \"metrics.raw_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64217803",
   "metadata": {},
   "source": [
    "It looks like we get the highest performance for sif_coefficient 0.005. But we should experiment with normalized embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083bcb1",
   "metadata": {},
   "source": [
    "### Larger added vocubalry increases performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = runs[(runs['tags.mlflow.runName'].str.contains(\"vocab\")) | (runs['tags.mlflow.runName'].str.contains(\"ignore_external\")) | (runs['tags.mlflow.runName']==\"dim256\")]\n",
    "rs = rs.groupby(\"tags.mlflow.runName\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90dae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(rs.reset_index(), x = \"params.vocab_size\", y = \"metrics.raw_accuracy\", color = \"tags.mlflow.runName\")\n",
    "fig.update_layout(barmode='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877cc8ff",
   "metadata": {},
   "source": [
    "Adding external tokens seems to increase performance. Pew. But it looks like performance increases slowly with vocab size. Here, vocab size is the number of added tokens which does not include internal tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f2399",
   "metadata": {},
   "source": [
    "### Unused internal tokens hurt performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12280b",
   "metadata": {},
   "source": [
    "Here we investigage the effect of stripping internal tokens. The tokenizer contains an internal vocabulary of ~150k tokens, must of which are never used. For example, tokens that are upper case are not possible to use because the pre-tokenizer removes them. During dimension reduction these tokens are equal to all other tokens despite not being important and this likely reduces the performance. \n",
    "\n",
    "Likewise, tokens containing exotic characters are very infrequently used and we investigate the effect of neglecting them. \n",
    "\n",
    "Finally, since there are a lot of tokens are very infrequently used (if used at all), we investigate the effect of neglecting their contribution to the variance when doing the dimension reduction. That way, only tokens seen in the training data is used to perform the dimension reduction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58168c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = runs[(runs['tags.mlflow.runName'].str.contains(\"strip\")) | (runs['tags.mlflow.runName']==\"dim256\")]\n",
    "rs = rs.groupby(\"tags.mlflow.runName\").first()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df273452",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(rs.reset_index(), x = \"tags.mlflow.runName\", y = \"metrics.raw_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4836e706",
   "metadata": {},
   "source": [
    "It looks like all these initiatives tend to improve the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d72d2",
   "metadata": {},
   "source": [
    "### Prenormalization treats tokens more fairly but hurts performance\n",
    "\n",
    "The raw output of the embeddings are not normalized and since they span large space, the tokens whose embeddings contribute to the variance are likely also the ones that are \"long\". In an effort to reduce this effect, it was also investigated how normalization of the individual token embeddings affect the performance. By normalizing, we \"remove\" information but we treat the tokens more \"fairly\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54146426",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = runs[(runs['tags.mlflow.runName'].str.contains(\"pre\")) | (runs['tags.mlflow.runName']==\"dim256\")]\n",
    "rs = rs.groupby(\"tags.mlflow.runName\").first()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b70c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(rs.reset_index(), x = \"tags.mlflow.runName\", y = \"metrics.raw_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e3fd0",
   "metadata": {},
   "source": [
    "It looks like all prenormalization hurts the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove lower-case tokens from output tokenizer vocab\n",
    "#python scripts/hyperparams.py --output-dim 256 --strip-upper-case\n",
    "\n",
    "# Remove both lower-case tokens and strip exotic tokens from tokenizer vocab\n",
    "#python scripts/hyperparams.py --output-dim 256 --strip-upper-case --strip-exotic\n",
    "\n",
    "# Focus dimension reduction (PCA) on the embeddings space that is represented in the corpus.\n",
    "#python scripts/hyperparams.py --output-dim 256 --strip-upper-case --strip-exotic --focus-pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments with different SIF coefficients\n",
    "#python scripts/hyperparams.py --output-dim 256 --sif-coefficient 0.01\n",
    "#python scripts/hyperparams.py --output-dim 256 --sif-coefficient 0.005\n",
    "#python scripts/hyperparams.py --output-dim 256 --sif-coefficient 0.001\n",
    "#python scripts/hyperparams.py --output-dim 256 --sif-coefficient 0.0005\n",
    "#python scripts/hyperparams.py --output-dim 256 --sif-coefficient 0.0001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkmodel2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
